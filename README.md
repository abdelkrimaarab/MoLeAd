# Gold Test Set Builder - MoLeAd

## üìã Description

Application Streamlit compl√®te pour constituer un **Gold Test Set** (V√©rit√© Terrain) conforme aux exigences des revues Q1. Cette application vous guide √† travers tout le processus de cr√©ation d'un ensemble de test de r√©f√©rence pour valider votre m√©thode d'annotation automatique (weak supervision).

## üéØ Objectifs

Prouver que votre m√©thode d'annotation automatique MoLeAd est fiable en la comparant √† une annotation humaine de haute qualit√©.

## üöÄ Installation

### Pr√©requis
- Python 3.8+
- Les donn√©es brutes dans `../data/dataset/legal_announcements.json`

### D√©pendances

```bash
pip install streamlit pandas numpy scikit-learn plotly
```

## üíª Lancement de l'application

```bash
cd "Gold Test Set"
streamlit run gold_test_set_app.py
```

L'application s'ouvrira automatiquement dans votre navigateur par d√©faut.

## üìä Workflow en 6 √©tapes

### 1Ô∏è‚É£ √âchantillonnage Stratifi√©
- S√©lection de **500 √† 1 000 annonces**
- Approche stratifi√©e pour garantir la repr√©sentation des classes rares
- Quota minimum configurable pour les cat√©gories minoritaires
- √âvite le biais vers les classes majoritaires

**Recommandation** : 1 000 documents est un standard solide pour une publication Q1

### 2Ô∏è‚É£ Annotation en Double Aveugle

#### 2a. Annotateur A
- Interface d'annotation intuitive
- Annotation ind√©pendante sans voir les pr√©dictions automatiques
- Suivi de progression en temps r√©el
- Niveau de confiance et notes optionnelles

#### 2b. Annotateur B
- M√™me interface que l'Annotateur A
- **Totalement ind√©pendant** - ne voit pas les annotations de A
- Garantit l'objectivit√© de l'√©valuation

**Important** : Les deux annotateurs doivent √™tre des experts juridiques ou des linguistes form√©s

### 3Ô∏è‚É£ Accord Inter-Annotateurs (IAA)

Calcul automatique de :
- **Cohen's Kappa** : Mesure standard de l'accord inter-annotateurs
- **Taux d'accord simple** : Pourcentage d'accords directs
- **Matrice de confusion** : Visualisation des d√©saccords
- **Identification automatique des conflits** √† r√©soudre

**Objectif** : Kappa > 0.8 (accord "fort" ou "presque parfait")

### 4Ô∏è‚É£ Adjudication

- Interface d√©di√©e pour le **super-annotateur** (expert tiers)
- Examine uniquement les d√©saccords entre A et B
- D√©cide de l'√©tiquette finale pour chaque conflit
- Justification optionnelle des d√©cisions
- Construction du **Gold Standard** final

### 5Ô∏è‚É£ √âvaluation des Performances

Comparaison automatique entre :
- **Silver Labels** : Annotations automatiques de MoLeAd
- **Gold Labels** : Annotations humaines valid√©es

#### M√©triques calcul√©es :

**Macro-Averaged** (traite toutes les classes de fa√ßon √©gale) :
- Precision
- Recall
- F1-Score

**Micro-Averaged** (pond√©r√© par la fr√©quence des classes) :
- Precision
- Recall
- F1-Score

**Globales** :
- Accuracy
- Matrice de confusion compl√®te
- Rapport de classification d√©taill√© par classe

**Analyse des erreurs** :
- Identification des erreurs sp√©cifiques
- Visualisation des patterns d'erreurs
- Top 10 des types d'erreurs les plus fr√©quents

### 6Ô∏è‚É£ Export & Rapport

**Exports disponibles** :
- Gold Standard (JSON et CSV)
- Annotations individuelles (A et B)
- D√©saccords pour analyse
- M√©triques de performance

**Rapport final** :
- Rapport Markdown complet
- M√©thodologie d√©taill√©e
- R√©sultats statistiques
- Pr√™t pour inclusion dans une publication scientifique

## üìÅ Structure des fichiers g√©n√©r√©s

```
Gold Test Set/
‚îú‚îÄ‚îÄ gold_test_set_app.py          # Application principale
‚îú‚îÄ‚îÄ README.md                      # Ce fichier
‚îî‚îÄ‚îÄ results/                       # Dossier auto-cr√©√©
    ‚îú‚îÄ‚îÄ sampled_data_*.json        # √âchantillon stratifi√©
    ‚îú‚îÄ‚îÄ annotator_a_*.json         # Annotations de A
    ‚îú‚îÄ‚îÄ annotator_b_*.json         # Annotations de B
    ‚îú‚îÄ‚îÄ disagreements_*.csv        # Liste des d√©saccords
    ‚îú‚îÄ‚îÄ gold_standard_final_*.json # Gold Standard final
    ‚îú‚îÄ‚îÄ gold_standard_final_*.csv  # Gold Standard (CSV)
    ‚îî‚îÄ‚îÄ rapport_final_*.md         # Rapport complet
```

## üéì Standards pour publication Q1

### M√©thodologie √† inclure dans l'article

1. **√âchantillonnage** :
   ```
   "Un √©chantillon stratifi√© de 1 000 annonces l√©gales a √©t√© constitu√©, 
   garantissant une repr√©sentation √©quilibr√©e de toutes les cat√©gories, 
   avec un quota minimum de 50 instances pour les classes rares."
   ```

2. **Annotation** :
   ```
   "Deux annotateurs experts ind√©pendants ont √©tiquet√© l'ensemble de 
   l'√©chantillon en double-aveugle, sans acc√®s aux pr√©dictions du syst√®me 
   automatique."
   ```

3. **IAA** :
   ```
   "L'accord inter-annotateurs, mesur√© par le Cohen's Kappa, √©tait de Œ∫ = X.XX, 
   indiquant un accord [substantiel/fort/presque parfait]."
   ```

4. **Adjudication** :
   ```
   "Les X d√©saccords ont √©t√© r√©solus par un expert tiers ind√©pendant, 
   constituant le Gold Standard final de r√©f√©rence."
   ```

5. **R√©sultats** :
   ```
   "Compar√© au Gold Standard, notre syst√®me MoLeAd a atteint une pr√©cision 
   macro-moyenne de X.XX, un rappel de X.XX et un F1-Score de X.XX."
   ```

### Tableaux et figures recommand√©s

1. **Tableau 1** : Distribution des cat√©gories dans l'√©chantillon
2. **Tableau 2** : Matrice de confusion inter-annotateurs
3. **Tableau 3** : M√©triques de performance par cat√©gorie
4. **Figure 1** : Matrice de confusion Gold vs. Silver
5. **Figure 2** : Distribution des erreurs par type

## üîç Interpr√©tation des r√©sultats

### Cohen's Kappa
- **Œ∫ < 0.20** : Accord faible ‚Üí R√©viser la taxonomie
- **0.20 ‚â§ Œ∫ < 0.40** : Accord moyen ‚Üí Am√©liorer les guidelines
- **0.40 ‚â§ Œ∫ < 0.60** : Accord mod√©r√© ‚Üí Clarifier les cas ambigus
- **0.60 ‚â§ Œ∫ < 0.80** : Accord substantiel ‚Üí Acceptable pour Q1
- **Œ∫ ‚â• 0.80** : Accord fort/presque parfait ‚Üí Excellent pour Q1

### F1-Score
- **F1 > 0.80** : Excellent syst√®me
- **0.70 ‚â§ F1 ‚â§ 0.80** : Bon syst√®me, marges d'am√©lioration
- **0.60 ‚â§ F1 < 0.70** : Syst√®me acceptable, n√©cessite optimisation
- **F1 < 0.60** : Syst√®me n√©cessite r√©vision importante

## üìö R√©f√©rences scientifiques

Pour justifier votre m√©thodologie dans l'article :

1. **Cohen's Kappa** :
   - Cohen, J. (1960). "A coefficient of agreement for nominal scales"

2. **√âchantillonnage stratifi√©** :
   - Cochran, W. G. (1977). "Sampling techniques"

3. **Annotation en double-aveugle** :
   - Artstein, R., & Poesio, M. (2008). "Inter-coder agreement for computational linguistics"

4. **Weak Supervision** :
   - Ratner, A., et al. (2017). "Snorkel: Rapid training data creation with weak supervision"

## üõ†Ô∏è Personnalisation

### Modifier les cat√©gories d'annotation

Dans `gold_test_set_app.py`, ligne ~380 et ~450, modifiez :
```python
options=["", "Cr√©ation", "Modification", "Dissolution", "Fusion/Scission", "Autre"]
```

### Ajuster les seuils d'√©chantillonnage

Dans la fonction `stratified_sampling()` :
```python
threshold = len(df) * 0.05  # 5% du total = classe rare
```

### Personnaliser les exports

Modifiez les fonctions d'export dans la section "Page 6: Export"

## ‚ö†Ô∏è Bonnes pratiques

1. **Formation des annotateurs** :
   - Organisez une session de formation avant l'annotation
   - Fournissez un guide d'annotation d√©taill√©
   - Utilisez des exemples pour chaque cat√©gorie

2. **Qualit√© avant quantit√©** :
   - Mieux vaut 500 annotations de haute qualit√© que 2000 m√©diocres
   - Encouragez les pauses r√©guli√®res

3. **Documentation** :
   - Documentez toutes les d√©cisions m√©thodologiques
   - Conservez les justifications d'adjudication
   - Notez les cas difficiles pour discussion

4. **Validation crois√©e** :
   - Envisagez plusieurs annotateurs pour les cas tr√®s ambigus
   - Discutez des d√©saccords syst√©matiques en √©quipe

## üêõ D√©pannage

### Erreur de chargement des donn√©es
```
V√©rifiez que le fichier legal_announcements.json existe dans :
../data/dataset/legal_announcements.json
```

### Application lente
```
L'application peut √™tre lente avec de tr√®s gros fichiers.
Envisagez de cr√©er un √©chantillon pr√©liminaire plus petit.
```

## üìû Support

Pour toute question ou probl√®me :
1. Consultez la documentation Streamlit : https://docs.streamlit.io
2. V√©rifiez les logs dans le terminal
3. Assurez-vous que toutes les d√©pendances sont install√©es

## üìú Licence

Ce projet fait partie du syst√®me MoLeAd pour l'extraction et la classification automatique d'annonces l√©gales.

## ‚ú® Am√©liorations futures

- [ ] Support multi-langues
- [ ] Export au format LaTeX pour articles
- [ ] Int√©gration avec des outils d'annotation comme Label Studio
- [ ] Calcul automatique de la taille d'√©chantillon optimale
- [ ] Support du Fleiss' Kappa pour >2 annotateurs
- [ ] G√©n√©ration automatique de graphiques pour publication
- [ ] API REST pour int√©gration dans d'autres syst√®mes

---

**D√©velopp√© pour le projet MoLeAd - 2026**

*Conforme aux standards des revues Q1 en NLP et Machine Learning*
